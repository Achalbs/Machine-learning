{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30cf82f-48fa-4d1d-90cd-d05fe699a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535e2e6-1dec-449a-bf7b-f157bb2dd208",
   "metadata": {},
   "source": [
    "Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02856c8c-e257-4a41-a3d0-7aa0c507613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2784026-b9ae-48d1-b833-b7cba48348dc",
   "metadata": {},
   "source": [
    "Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09316087-7364-43af-8ce4-1721f74dfecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\\n\", X.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b59bd9-f701-4119-b376-6cec7a608850",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360964eb-8c02-4cb4-bd7a-9515a81e407f",
   "metadata": {},
   "source": [
    "Split into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452b1974-bcd9-49e2-95f5-467a17071258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f06c5-6583-47f5-ad5b-a3f832ef7f12",
   "metadata": {},
   "source": [
    "Feature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502950c1-331a-4fb2-af8b-ca5271b78fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Models to Implement\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a468b5ef-15d0-4e7d-bf91-981a704b92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b77000b0-8bec-498f-ba92-273b3f5d7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, predict, and evaluate models\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b58744b2-6167-4e16-8aa8-95456f78932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03ee3871-37b8-486c-8894-6734d9a33019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">************ Logistic Regression ***********</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:green; font-size:18px; font-weight:bold;\">Accuracy: 0.97368421</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">************ Decision Tree ***********</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:green; font-size:18px; font-weight:bold;\">Accuracy: 0.94736842</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">************ Random Forest ***********</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:green; font-size:18px; font-weight:bold;\">Accuracy: 0.96491228</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">************ Support Vector Machine ***********</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:green; font-size:18px; font-weight:bold;\">Accuracy: 0.97368421</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">************ k-Nearest Neighbors ***********</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:green; font-size:18px; font-weight:bold;\">Accuracy: 0.94736842</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results.append({\"Model\": name, \"Accuracy\": acc})\n",
    "\n",
    "    display(HTML(f'<span style=\"color:blue; font-size:18px; font-weight:bold;\">************ {name} ***********</span>'))\n",
    "    display(HTML(f'<span style=\"color:green; font-size:18px; font-weight:bold;\">Accuracy: {acc:.8f}</span>'))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7d454-7b6d-4651-93b6-6d8cfb15c7d6",
   "metadata": {},
   "source": [
    "Compare Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9fec4a9-229b-49e3-89fe-fdcf507ff036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-size:18px; font-weight:bold;\">************  Model Performance Comparison: \n",
       " ***********</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                    Model  Accuracy\n",
      "0     Logistic Regression  0.973684\n",
      "3  Support Vector Machine  0.973684\n",
      "2           Random Forest  0.964912\n",
      "1           Decision Tree  0.947368\n",
      "4     k-Nearest Neighbors  0.947368\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\\n\")\n",
    "display(HTML(f'<span style=\"color:blue; font-size:18px; font-weight:bold;\">************  Model Performance Comparison: \\n ***********</span>'))\n",
    "print(\"\\n\\n\")\n",
    "print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "#print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a1a8c-d3a4-4773-84fc-c549457435fc",
   "metadata": {},
   "source": [
    "Best and Worst Performing Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dbe4580-bfc5-45b2-b86a-613a741e0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "worst_model = results_df.loc[results_df['Accuracy'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6223aa77-8a35-4a47-8731-6fef15c7d0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-weight:bold; font-size:18px\">Best Performing Model</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model       Logistic Regression\n",
      "Accuracy               0.973684\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "display(HTML('<span style=\"color:blue; font-weight:bold; font-size:18px\">Best Performing Model</span>'))\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "651d601d-87ab-4452-9ccb-20ff96d512eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; font-weight:bold; font-size:18px\">Worst Performing Model</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model       Decision Tree\n",
      "Accuracy         0.947368\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "display(HTML('<span style=\"color:blue; font-weight:bold; font-size:18px\">Worst Performing Model</span>'))\n",
    "print(worst_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728f5c2-2189-434d-b111-95769bc7c17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775ade5-cfbb-4e24-8b74-525a0ecd58a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
